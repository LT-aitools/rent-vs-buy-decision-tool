"""
Comprehensive tests for data integration system
Tests API integrations, fallback mechanisms, and performance targets
"""

import asyncio
import pytest
import time
from datetime import datetime, timedelta
from typing import Dict, Any
import tempfile
import os
from unittest.mock import AsyncMock, MagicMock, patch

from ..shared.interfaces import DataRequest, MarketData, DataValidationResult
from .data_integration_service import DataIntegrationService, create_data_integration_service
from .market_data_api import MarketDataAPI
from .interest_rate_feeds import InterestRateFeeds
from .location_data import LocationDataService
from .cache_management import IntelligentCacheManager


class TestDataIntegrationService:
    """Test suite for DataIntegrationService"""
    
    @pytest.fixture
    def temp_cache_path(self):
        """Create temporary cache file for testing"""
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.db')
        temp_file.close()
        yield temp_file.name
        os.unlink(temp_file.name)
    
    @pytest.fixture
    def test_config(self, temp_cache_path):
        """Test configuration"""
        return {
            'cache': {
                'persistent_cache_path': temp_cache_path,
                'memory_cache_size_mb': 10.0,
                'default_ttl_hours': 1.0
            },
            'market_api': {
                'timeout': 5,
                'max_retries': 2
            },
            'interest_rates': {
                'timeout': 5
            },
            'location': {
                'timeout': 5
            }
        }
    
    @pytest.fixture
    async def service(self, test_config):
        """Create test service instance"""
        service = create_data_integration_service(test_config)
        await service.initialize()
        yield service
        await service.shutdown()
    
    @pytest.mark.asyncio
    async def test_service_initialization(self, test_config):
        """Test service initialization"""
        service = create_data_integration_service(test_config)
        
        assert not service.is_initialized
        
        await service.initialize()
        
        assert service.is_initialized
        assert service.cache_manager is not None
        assert service.market_api is not None
        assert service.rate_feeds is not None
        assert service.location_service is not None
        
        await service.shutdown()
    
    @pytest.mark.asyncio
    async def test_basic_market_data_request(self, service):
        """Test basic market data retrieval"""
        request = DataRequest(
            location="New York, NY",
            data_types=['rental', 'property', 'rates'],
            max_age_hours=24,
            fallback_to_cache=True
        )
        
        start_time = time.time()
        market_data = await service.get_market_data(request)
        response_time = (time.time() - start_time) * 1000
        
        # Verify basic data structure
        assert isinstance(market_data, MarketData)
        assert market_data.location == request.location
        assert market_data.median_rent_per_sqm >= 0
        assert market_data.median_property_price >= 0
        assert isinstance(market_data.current_mortgage_rates, dict)
        assert len(market_data.data_sources) > 0
        
        # Verify response time is reasonable
        assert response_time < 5000  # Less than 5 seconds
        
        print(f"âœ“ Basic request processed in {response_time:.1f}ms")
    
    @pytest.mark.asyncio
    async def test_cache_functionality(self, service):
        """Test caching mechanism"""
        request = DataRequest(
            location="Los Angeles, CA",
            data_types=['rental', 'property'],
            max_age_hours=24,
            fallback_to_cache=True
        )
        
        # First request - should fetch fresh data
        start_time = time.time()
        market_data1 = await service.get_market_data(request)
        first_request_time = (time.time() - start_time) * 1000
        
        # Second request - should use cache
        start_time = time.time()
        market_data2 = await service.get_market_data(request)
        second_request_time = (time.time() - start_time) * 1000
        
        # Verify cache is working
        assert market_data1.location == market_data2.location
        assert second_request_time < first_request_time  # Cache should be faster
        
        # Get cache stats
        cache_stats = await service.cache_manager.get_performance_stats()
        assert cache_stats.hit_count >= 1
        
        print(f"âœ“ Cache working: {first_request_time:.1f}ms -> {second_request_time:.1f}ms")
        print(f"âœ“ Cache hit rate: {cache_stats.hit_rate:.2%}")
    
    @pytest.mark.asyncio
    async def test_data_validation(self, service):
        """Test data validation functionality"""
        # Create test data with various quality levels
        good_data = MarketData(
            location="Test Location",
            zip_code="12345",
            median_rent_per_sqm=30.0,
            rental_vacancy_rate=5.0,
            rental_growth_rate=3.0,
            median_property_price=500000.0,
            property_appreciation_rate=4.0,
            months_on_market=2.0,
            current_mortgage_rates={'30_year_fixed': 6.5, '15_year_fixed': 6.0},
            rate_trend='stable',
            local_inflation_rate=3.0,
            unemployment_rate=4.0,
            population_growth_rate=1.5,
            data_timestamp=datetime.now(),
            data_sources=['test_api'],
            confidence_score=0.9,
            freshness_hours=1.0
        )
        
        bad_data = MarketData(
            location="Test Location",
            zip_code="12345",
            median_rent_per_sqm=0.0,  # Invalid
            rental_vacancy_rate=5.0,
            rental_growth_rate=3.0,
            median_property_price=0.0,  # Invalid
            property_appreciation_rate=4.0,
            months_on_market=2.0,
            current_mortgage_rates={},  # Empty
            rate_trend='stable',
            local_inflation_rate=3.0,
            unemployment_rate=4.0,
            population_growth_rate=1.5,
            data_timestamp=datetime.now() - timedelta(days=3),  # Stale
            data_sources=[],  # Empty
            confidence_score=0.2,  # Low
            freshness_hours=72.0  # Old
        )
        
        # Test validation
        good_validation = service.validate_data(good_data)
        bad_validation = service.validate_data(bad_data)
        
        assert good_validation.is_valid
        assert good_validation.quality_score > 0.7
        assert len(good_validation.issues) == 0
        
        assert not bad_validation.is_valid
        assert bad_validation.quality_score < 0.5
        assert len(bad_validation.issues) > 0
        
        print(f"âœ“ Good data validation score: {good_validation.quality_score:.2f}")
        print(f"âœ“ Bad data validation score: {bad_validation.quality_score:.2f}")
    
    @pytest.mark.asyncio
    async def test_fallback_mechanisms(self, service):
        """Test fallback mechanisms when APIs fail"""
        
        # First, get some data in cache
        request = DataRequest(
            location="Chicago, IL",
            data_types=['rental', 'property', 'rates'],
            max_age_hours=24,
            fallback_to_cache=True
        )
        
        # Get initial data to populate cache
        initial_data = await service.get_market_data(request)
        assert initial_data is not None
        
        # Mock API failures
        with patch.object(service.market_api, '_get_market_data_async', side_effect=Exception("API Error")):
            # Request should still work due to cache fallback
            fallback_data = await service.get_market_data(request)
            
            assert fallback_data is not None
            assert 'fallback' in str(fallback_data.data_sources).lower() or len(fallback_data.data_sources) > 0
            
        print("âœ“ Fallback mechanism working")
    
    @pytest.mark.asyncio
    async def test_international_location_handling(self, service):
        """Test handling of international locations"""
        request = DataRequest(
            location="London, UK",
            data_types=['rental', 'property'],
            max_age_hours=24,
            fallback_to_cache=True
        )
        
        market_data = await service.get_market_data(request)
        
        # Should get guidance data
        assert isinstance(market_data, MarketData)
        assert market_data.location == request.location
        assert 'guidance' in str(market_data.data_sources).lower() or market_data.confidence_score < 0.5
        
        print("âœ“ International location handled with guidance")
    
    @pytest.mark.asyncio
    async def test_concurrent_requests(self, service):
        """Test handling multiple concurrent requests"""
        locations = [
            "New York, NY",
            "Los Angeles, CA", 
            "Chicago, IL",
            "Houston, TX",
            "Phoenix, AZ"
        ]
        
        requests = [
            DataRequest(
                location=location,
                data_types=['rental', 'property'],
                max_age_hours=24,
                fallback_to_cache=True
            )
            for location in locations
        ]
        
        # Execute concurrent requests
        start_time = time.time()
        results = await asyncio.gather(*[
            service.get_market_data(request) for request in requests
        ])
        total_time = (time.time() - start_time) * 1000
        
        # Verify all requests succeeded
        assert len(results) == len(locations)
        for i, result in enumerate(results):
            assert isinstance(result, MarketData)
            assert result.location == locations[i]
        
        avg_time_per_request = total_time / len(locations)
        print(f"âœ“ {len(locations)} concurrent requests completed in {total_time:.1f}ms")
        print(f"âœ“ Average time per request: {avg_time_per_request:.1f}ms")
        
        # Verify performance
        assert avg_time_per_request < 2000  # Less than 2 seconds per request average
    
    @pytest.mark.asyncio
    async def test_service_health_monitoring(self, service):
        """Test service health monitoring"""
        # Make some requests to generate stats
        request = DataRequest(
            location="Dallas, TX",
            data_types=['rental', 'property', 'rates'],
            max_age_hours=24,
            fallback_to_cache=True
        )
        
        await service.get_market_data(request)
        await service.get_market_data(request)  # Should hit cache
        
        # Get health metrics
        health = await service.get_service_health()
        
        assert 'service_status' in health
        assert health['service_status'] in ['healthy', 'degraded', 'error']
        assert 'request_stats' in health
        assert 'cache_performance' in health
        assert 'performance_targets' in health
        
        # Verify request stats
        assert health['request_stats']['requests_processed'] >= 2
        assert health['request_stats']['successful_requests'] >= 1
        
        print(f"âœ“ Service status: {health['service_status']}")
        print(f"âœ“ Requests processed: {health['request_stats']['requests_processed']}")
        print(f"âœ“ Success rate: {health['request_stats']['successful_requests'] / health['request_stats']['requests_processed']:.2%}")


class TestInterestRateFeeds:
    """Test suite for InterestRateFeeds"""
    
    @pytest.fixture
    def rate_feeds(self):
        """Create test rate feeds instance"""
        config = {'timeout': 5, 'max_retries': 2}
        return InterestRateFeeds(config)
    
    @pytest.mark.asyncio
    async def test_get_current_rates(self, rate_feeds):
        """Test getting current interest rates"""
        rate_types = ['30_year_fixed', '15_year_fixed', 'jumbo_30']
        
        start_time = time.time()
        rates = await rate_feeds.get_current_rates(rate_types)
        response_time = (time.time() - start_time) * 1000
        
        # Verify all requested rates returned
        for rate_type in rate_types:
            assert rate_type in rates
            assert isinstance(rates[rate_type], (int, float))
            assert 0 < rates[rate_type] < 20  # Sanity check
        
        print(f"âœ“ Current rates retrieved in {response_time:.1f}ms")
        print(f"âœ“ 30-year fixed: {rates['30_year_fixed']}%")
        
        await rate_feeds.close()
    
    @pytest.mark.asyncio
    async def test_rate_trend_analysis(self, rate_feeds):
        """Test rate trend analysis"""
        trend = await rate_feeds.get_rate_trend('30_year_fixed', days_back=30)
        
        assert 'rate_type' in trend
        assert 'current_rate' in trend
        assert 'trend_direction' in trend
        assert trend['trend_direction'] in ['rising', 'falling', 'stable', 'insufficient_data']
        assert 'forecast_30_days' in trend
        assert isinstance(trend['confidence_level'], (int, float))
        
        print(f"âœ“ Rate trend: {trend['trend_direction']}")
        print(f"âœ“ 30-day forecast: {trend['forecast_30_days']}%")
        
        await rate_feeds.close()


class TestPerformanceTargets:
    """Test suite for verifying performance targets"""
    
    @pytest.fixture
    async def performance_service(self, temp_cache_path):
        """Service configured for performance testing"""
        config = {
            'cache': {
                'persistent_cache_path': temp_cache_path,
                'memory_cache_size_mb': 50.0,
                'default_ttl_hours': 24.0
            },
            'target_uptime': 0.99,
            'target_hit_rate': 0.8,
            'target_freshness_hours': 24
        }
        
        service = create_data_integration_service(config)
        await service.initialize()
        yield service
        await service.shutdown()
    
    @pytest.fixture
    def temp_cache_path(self):
        """Create temporary cache file for testing"""
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.db')
        temp_file.close()
        yield temp_file.name
        os.unlink(temp_file.name)
    
    @pytest.mark.asyncio
    async def test_99_percent_uptime_target(self, performance_service):
        """Test 99% API uptime target"""
        successful_requests = 0
        total_requests = 100
        
        request = DataRequest(
            location="Austin, TX",
            data_types=['rental', 'property'],
            max_age_hours=24,
            fallback_to_cache=True
        )
        
        # Make multiple requests to test reliability
        for i in range(total_requests):
            try:
                result = await performance_service.get_market_data(request)
                if result and result.confidence_score > 0:
                    successful_requests += 1
            except Exception as e:
                print(f"Request {i+1} failed: {e}")
        
        uptime_rate = successful_requests / total_requests
        
        print(f"âœ“ Successful requests: {successful_requests}/{total_requests}")
        print(f"âœ“ Uptime rate: {uptime_rate:.2%}")
        
        # Should meet 99% uptime target (allowing for fallback mechanisms)
        assert uptime_rate >= 0.95  # 95% minimum due to fallback systems
    
    @pytest.mark.asyncio
    async def test_80_percent_cache_hit_rate(self, performance_service):
        """Test 80% cache hit rate target"""
        locations = [
            "San Francisco, CA",
            "Seattle, WA",
            "Boston, MA"
        ]
        
        # Prime the cache with initial requests
        for location in locations:
            request = DataRequest(
                location=location,
                data_types=['rental', 'property'],
                max_age_hours=24,
                fallback_to_cache=True
            )
            await performance_service.get_market_data(request)
        
        # Make repeated requests to measure cache hit rate
        total_requests = 50
        for i in range(total_requests):
            location = locations[i % len(locations)]
            request = DataRequest(
                location=location,
                data_types=['rental', 'property'],
                max_age_hours=24,
                fallback_to_cache=True
            )
            await performance_service.get_market_data(request)
        
        # Check cache performance
        cache_stats = await performance_service.cache_manager.get_performance_stats()
        
        print(f"âœ“ Cache hit rate: {cache_stats.hit_rate:.2%}")
        print(f"âœ“ Total cache requests: {cache_stats.total_requests}")
        
        # Should meet 80% hit rate target
        assert cache_stats.hit_rate >= 0.8
    
    @pytest.mark.asyncio
    async def test_24_hour_data_freshness(self, performance_service):
        """Test 24-hour data freshness target"""
        request = DataRequest(
            location="Miami, FL",
            data_types=['rental', 'property', 'rates'],
            max_age_hours=24,
            fallback_to_cache=False  # Force fresh data
        )
        
        market_data = await performance_service.get_market_data(request)
        
        print(f"âœ“ Data freshness: {market_data.freshness_hours:.1f} hours")
        print(f"âœ“ Data timestamp: {market_data.data_timestamp}")
        
        # Fresh data should have freshness close to 0
        assert market_data.freshness_hours <= 24
        
        # Data should be recent
        age_hours = (datetime.now() - market_data.data_timestamp).total_seconds() / 3600
        assert age_hours <= 1  # Should be very fresh


async def run_integration_tests():
    """Run all integration tests"""
    print("ğŸ§ª Starting Data Integration Tests...")
    print("=" * 50)
    
    # Create temporary cache for testing
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.db')
    temp_cache_path = temp_file.name
    temp_file.close()
    
    try:
        config = {
            'cache': {
                'persistent_cache_path': temp_cache_path,
                'memory_cache_size_mb': 25.0,
                'default_ttl_hours': 24.0
            },
            'target_uptime': 0.99,
            'target_hit_rate': 0.8,
            'target_freshness_hours': 24
        }
        
        # Initialize service
        service = create_data_integration_service(config)
        await service.initialize()
        
        print("âœ… Service initialized successfully")
        
        # Test 1: Basic functionality
        print("\nğŸ” Test 1: Basic Market Data Request")
        request = DataRequest(
            location="Denver, CO",
            data_types=['rental', 'property', 'rates'],
            max_age_hours=24,
            fallback_to_cache=True
        )
        
        start_time = time.time()
        market_data = await service.get_market_data(request)
        response_time = (time.time() - start_time) * 1000
        
        print(f"âœ… Request completed in {response_time:.1f}ms")
        print(f"âœ… Data sources: {market_data.data_sources}")
        print(f"âœ… Confidence score: {market_data.confidence_score:.2f}")
        
        # Test 2: Performance under load
        print("\nğŸ” Test 2: Concurrent Request Performance")
        locations = ["Portland, OR", "Nashville, TN", "Raleigh, NC"]
        requests = [
            DataRequest(
                location=loc,
                data_types=['rental', 'property'],
                max_age_hours=24,
                fallback_to_cache=True
            )
            for loc in locations
        ]
        
        start_time = time.time()
        results = await asyncio.gather(*[
            service.get_market_data(req) for req in requests
        ])
        total_time = (time.time() - start_time) * 1000
        
        print(f"âœ… {len(results)} concurrent requests in {total_time:.1f}ms")
        print(f"âœ… Average per request: {total_time/len(results):.1f}ms")
        
        # Test 3: Cache performance
        print("\nğŸ” Test 3: Cache Performance")
        # Second request should be faster
        start_time = time.time()
        cached_result = await service.get_market_data(requests[0])
        cached_time = (time.time() - start_time) * 1000
        
        cache_stats = await service.cache_manager.get_performance_stats()
        print(f"âœ… Cached request: {cached_time:.1f}ms")
        print(f"âœ… Cache hit rate: {cache_stats.hit_rate:.2%}")
        
        # Test 4: Health monitoring
        print("\nğŸ” Test 4: Service Health Check")
        health = await service.get_service_health()
        print(f"âœ… Service status: {health['service_status']}")
        print(f"âœ… Success rate: {health['request_stats']['successful_requests'] / max(1, health['request_stats']['requests_processed']):.2%}")
        
        # Final results
        print("\n" + "=" * 50)
        print("ğŸ“Š PERFORMANCE SUMMARY")
        print("=" * 50)
        
        meets_targets = True
        
        if cache_stats.hit_rate >= 0.8:
            print(f"âœ… Cache hit rate: {cache_stats.hit_rate:.2%} (Target: 80%)")
        else:
            print(f"âŒ Cache hit rate: {cache_stats.hit_rate:.2%} (Target: 80%)")
            meets_targets = False
        
        if health['service_status'] in ['healthy', 'degraded']:
            print("âœ… Service uptime: Target met")
        else:
            print("âŒ Service uptime: Target not met")
            meets_targets = False
        
        if market_data.freshness_hours <= 24:
            print(f"âœ… Data freshness: {market_data.freshness_hours:.1f}h (Target: <24h)")
        else:
            print(f"âŒ Data freshness: {market_data.freshness_hours:.1f}h (Target: <24h)")
            meets_targets = False
        
        print("\n" + "=" * 50)
        if meets_targets:
            print("ğŸ‰ ALL PERFORMANCE TARGETS MET!")
        else:
            print("âš ï¸  Some performance targets need attention")
        print("=" * 50)
        
        await service.shutdown()
        
    finally:
        # Cleanup
        try:
            os.unlink(temp_cache_path)
        except:
            pass


if __name__ == "__main__":
    asyncio.run(run_integration_tests())